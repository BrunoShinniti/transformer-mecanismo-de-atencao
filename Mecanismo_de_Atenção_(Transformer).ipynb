{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMILinJOqRuvfyXXPkfxhCV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BrunoShinniti/transformer-mecanismo-de-atencao/blob/main/Mecanismo_de_Aten%C3%A7%C3%A3o_(Transformer).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## com PyTorch"
      ],
      "metadata": {
        "id": "kAG0LIjJvypI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eo9PNkd0cTI-",
        "outputId": "27e4bb83-5d2e-48d0-f9b4-8d110ac0d2de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m94.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m73.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m118.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m110.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.1.0+cu118 requires torch==2.1.0, but you have torch 2.1.1 which is incompatible.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.1.1 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.1.1 which is incompatible.\n",
            "torchvision 0.16.0+cu118 requires torch==2.1.0, but you have torch 2.1.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q -U torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn"
      ],
      "metadata": {
        "id": "r_g0v5MDcdrH"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embedding_dim, n_heads, n_layers, dropout):\n",
        "        super().__init__()\n",
        "\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.n_heads = n_heads\n",
        "        self.n_layers = n_layers\n",
        "        self.drouptout = dropout\n",
        "\n",
        "        # Define a camada de embedding que transformará a sequência de entrada em uma sequência de vetores de dimensão fixa\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        # Define o mecanismo de auto-atenção multi-head\n",
        "        self.attention = nn.MultiheadAttention(embedding_dim, n_heads, dropout = dropout)\n",
        "\n",
        "        # Define a rede neural feed-forward qe será usada para gerar a sequência de saída a partir da sequência de entrada\n",
        "        self.feed_forward = nn.Sequential(\n",
        "            nn.Linear(embedding_dim, embedding_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(embedding_dim, embedding_dim)\n",
        "        )\n",
        "\n",
        "        # Define a camada de saída final que transformará a sequência de saída na forma de saída desejada\n",
        "        self.out = nn.Linear(embedding_dim, vocab_size)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # Aplica a camada de embedding à sequência de entrada\n",
        "        x = self.embedding(x)\n",
        "\n",
        "        # Aplica o mecanismo multi-headed self-attetion\n",
        "        x = self.attention(x)\n",
        "\n",
        "        # Aplica o método feed-forward\n",
        "        x = self.feed_forward(x)\n",
        "\n",
        "        # Aplica camada final\n",
        "        x = self.out(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "modelo = Transformer(vocab_size = 1000,\n",
        "                     embedding_dim = 32,\n",
        "                     n_heads = 4,\n",
        "                     n_layers = 2,\n",
        "                     dropout = 0.5)\n",
        "\n",
        "modelo.modules"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rS-MnpHbcdl-",
        "outputId": "14453091-88d4-43df-81de-1658e32ba85d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Module.modules of Transformer(\n",
              "  (embedding): Embedding(1000, 32)\n",
              "  (attention): MultiheadAttention(\n",
              "    (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
              "  )\n",
              "  (feed_forward): Sequential(\n",
              "    (0): Linear(in_features=32, out_features=32, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=32, out_features=32, bias=True)\n",
              "  )\n",
              "  (out): Linear(in_features=32, out_features=1000, bias=True)\n",
              ")>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelo.attention"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMdsPmrCcdg-",
        "outputId": "3cc3f75c-4b91-4c79-ca71-a327db5c5840"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultiheadAttention(\n",
              "  (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sem Framework\n",
        "\n",
        "Construção de modelo capaz de prever sequências de comprimento igual a 10 tokens.\n",
        "\n",
        "* 1 - Camada de Embedding: Transforma as palavras em vetores numéricos de tamanho fixo.\n",
        "\n",
        "* 2 - Mecanismo de Atenção: Permite que o modelo foque em diferentes partes da entrada.\n",
        "\n",
        "* 3 - Camadas Encoder e Decoder: Processam os dados sequencialmente\n",
        "\n",
        "* 4 - Camada Linear e Softmax: Para predições finais\n",
        "\n",
        "#### Objetivo:\n",
        "Implementar o item 2, mas para deixar o exemplo funcional, será implementado os itens 1 e 4."
      ],
      "metadata": {
        "id": "vxosJYhQvwYg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hiperparâmetros Iniciais"
      ],
      "metadata": {
        "id": "fgTydZXUwkxH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "4Id7O91FcdeH"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dimensão do modelo\n",
        "dim_model = 64"
      ],
      "metadata": {
        "id": "T8EI6eS4cdba"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Comprimento da sequência\n",
        "seq_lenght = 10"
      ],
      "metadata": {
        "id": "G2s9JlTvcdYn"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LSyWVc7acdVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3ynwlxjKcdTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QdygZXJTcdQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1KjWAXYEcdNy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8vofsVGYcdLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9Ac30c5AcdIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rPnXnumFcdF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uLhiyjF0cdDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iF8qrnPGcdBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6mqFd-QUcc_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xZzqlpuOcc8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xZ9hHU4Bcc6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RboOJuvncc4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z0JbQargcc1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fHJqEvPrccy_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}